---
layout: note
title: "The Common Sense Unit of Work - AI Productivity Measurement"
date: 2026-01-30
updated: 2026-01-30
status: budding
attribution: curated
authors: ["Nilenso Blog", "Claude (AI Assistant)"]
source: "https://blog.nilenso.com/blog/2025/09/17/the-common-sense-unit-of-work/?ref=sidebar"
summary: "Getting the abstraction for 'unit of work' wrong causes exponential complexity. AI productivity gains should be measured by valuable customer outcomes (user stories), not % of code generated. A well-defined unit of work benefits both humans and AI assistants."
tags: [AI, productivity, agile, software-development, measurement, user-stories]
---

## Core Argument

If we model software development in code, the **unit of work** would be the fundamental abstraction.

**Get this abstraction wrong** → complexity scales exponentially → all processes inherit dysfunction → planning becomes chaotic, progress opaque, coordination expensive.

**Why not refactor this abstraction** like we do with leaky code abstractions?

## Properties of a Good Unit of Work

Through familiar SDLC activities, key properties emerge:

### 1. Valuable Slice, Not Layer

Break features into parts that provide **value to customer** (slice of cake, not a layer).

Need steady sense of progress + validate business hypothesis early.

Bug fixes/refactors don't provide value the same way - that's okay. No need for dogma.

### 2. Negotiable Size

- **Before work starts**: Need to prioritize by weighing value vs. effort
- **Large slices with low value**: Break into smaller prioritized pieces
- **Large slices that can't be broken**: That's okay
- **Small slices that aren't independent**: Build larger slice anyway

Unit needs to be **negotiable**.

### 3. Independent Enough

As independent as possible so team members can work without blocking each other.

### 4. Gathers Context

A unit travels through time - specified today, picked up next month, blocked, deprioritised.

Over its life, gathers context:
- What value it provides, how to verify
- How it needs to be implemented
- Missing context resolved through conversations
- Unknowns resolved or unresolved
- Who worked on it, what issues arose
- Bugs in testing/QA

**Keep context in single place** → easier to pick up where left off.

### 5. Clear Acceptance Criteria

Know exactly what we're solving for → build just enough software™️.

Define criteria we can all agree on. Solve until met.

Automate checking criteria (will check many times while solving).

### 6. Done = In Production

When is unit done? **When slice is served** - in hands of user, in production, potentially behind feature flag.

## These Properties = User Story

Some would say INVEST in good units of work. Some recognize this as a **User Story**.

"As long as the described properties and affordances exist, it should make for a decent unit of work regardless of what we call it."

## The Refactoring Argument

Leaky abstractions in software → incidental complexity grows exponentially → whole system becomes slow, sludgy slop.

We can hack minor wins, but **big wins lost in ignored opportunities to refactor the central abstraction**.

**Apply to software development**: Our core abstraction (unit of work) might need refactoring.

## Measuring Productivity Correctly

### The Problem with DORA/Commit Frequency

DORA metrics (deploy/commit frequencies) may be valuable in some dimensions, but **not a measure of productivity in terms of outcomes for the customer**.

**Kent Beck on measuring developer productivity**:
> "Be suspicious of anyone claiming to measure developer productivity. Ask who is asking & why. Ask them what unit they are measuring & how those units are connected to profit.  
>   
> I am 100% pro-accountability. Weekly delivery of customer-appreciated value is the best accountability, the most aligned, the least distorting."

### AI Productivity Benchmarks Are Wrong

**Popularly reported**: % of code generated by AI  
**Why that's wrong**: Not a valuable dimension for measurement

**What would be right**: Benchmarks around **units of work valuable to the customer**.

If we measured AI productivity gains through customer-value units, we'd talk about **true productivity gains**:
- Prioritizing by value
- Eliminating unnecessary work
- Validating quickly

These become obvious, measurable ways to increase productivity.

## AI Assistants Need Good Units Too

**AI assistants also need small, well-specified slices of work**.

They benefit from well-defined units just like humans do.

The better your unit of work abstraction, the better AI can help with it.

(See related blog post by Atharva on AI + unit of work)

## Why This Matters Now

"Big gains in developer productivity in this economic weather are important."

Organizations measuring productivity need metrics **connected to profit** and **customer value**, not vanity metrics.

A well-defined unit of work enables:
- True productivity measurement (not just speed)
- Better AI assistance (clear, scoped work)
- Team alignment (shared artifact everyone discusses)
- Accountability through value delivery

## Connections

### Related Notes
- **[[task-size-relational]]** - Task size exists in relationship graphs, not intrinsically - why estimation is hard
- **[[programming-deflation]]** - Cheap code ≠ productivity; unit of work defines real gains
- **[[ai-code-craft-critique]]** - Technique (optimization) vs. craft (valuable outcomes)
- **[[literate-agents]]** - Threads as units of work + documentation
- **[[building-agents-still-hard]]** - Agents need well-scoped tasks (units) to succeed

## The Meta Point

"Yeah, this article is mostly about rehashing a two-decade-old pitch for some common sense agile."

But in the AI era, **common sense agile matters more than ever**:
- Commoditized code makes defining value critical
- AI accelerates implementation but doesn't define what's worth building
- Leaky unit-of-work abstractions now affect both human and AI productivity

## References

Classic Agile material:
- Kent Beck: XP Explained (Chapter 15 on planning)
- Bill Wake: INVEST criteria
- C2 Wiki: User Story
- Ron Jefferies: Card, Conversation, Confirmation
- Mike Cohn: User Stories Applied

---

**Curator's Note**: This is "old" agile wisdom that becomes newly urgent with AI. When code is cheap, **defining the right unit of work becomes the productivity bottleneck**. The critique of measuring AI productivity by % code generated is spot-on - we need outcome-based metrics, not activity metrics.

**Key insight**: AI productivity gains measured by code generation volume miss the point. True gains come from better units of work that prioritize value, eliminate waste, and validate quickly.

---
layout: essay
title: "You Should Have 'A Reasonable Starter Opinion' on How AI Will Change Your Industry"
subtitle: "Why every knowledge worker needs an informed perspective on AI's trajectory"
date: 2025-08-28
authors: ["Neil Shah"]
attribution: human-written
abstract: "For the past few years, we have been working with AI and AI tooling here at ThinkNimble. We've tested tools, tracked developments and watched as AI capabilities evolved from casual slack conversations to real things that we're applying in production environments with our clients."
readtime: "8 min"
tags: [ai, research, future-of-work]
---

For the past few years, we have been working with AI and AI tooling here at ThinkNimble. We've tested tools, tracked developments and watched as AI capabilities evolved from casual slack conversations to real things that we're applying in production environments with our clients. We have enough information that we are starting to collect and publish those items as an "unaccredited research lab" - a series of writings that share our genuine and hopefully thoughtful take on AI.

This feels like the right topic to start with, because one of the unexpected gifts that large AI companies have given us is transparency about their trajectory. Unlike previous technological revolutions that seemed to emerge suddenly, we can actually see AI development happening in real time, at a pace that's been remarkably steady and predictable.

I would like to assert that every knowledge worker should have an informed opinion on how and when AI will change their industry. It would be easy for this to be hyperbolic or hype-based ("AI is just a fad," or "AI is going to take all our jobs"), but much harder for this to be an informed, calculated opinion. But - if you believe that you will have to forecast your career, startup, non-profit or even the state of your industry, you **must** have some sort of opinion on this.

I think most people believe that AI will change the way that they work over the next many years. But exactly how or when this happens dramatically affects what you're doing now.

## What This Means by 2030

**No one definitively knows what will happen with AI.** We could be hitting a major plateau because we've run out of readily available data to train our models. Or maybe the major investment in AI data centers could lead to a massive boom in AI capabilities. Major governments could choose to regulate (or deregulate) AI significantly in the coming years.

Let's talk about a reasonably likely scenario. If we simply treat the last 5 years as the "default" rate of change for the next 5 years, and extend current trends, it's reasonable that we will see:

- AI systems that can perform (at least) most generative knowledge work tasks at human levels
- Integration of AI into many widely-used software tool and platform
- Autonomous agents capable of managing complex, multi-step workflows
- AI tutors, researchers, and collaborators that are available 24/7 to anyone with internet access

These may be incredible. They may be limited. They may require humans or they may not.

**I don't know exactly the degree of the change in front of us.** The specifics matter less than the direction. But the direction seems clear to me. We have had a consistent trendline of progress and it seems like that will continue.

A scenario where this progress suddenly halts or reverses seems less likely. It's not impossible, but for me to believe this, I'd need to see enough evidence to contradict what I see in front of me.

The assumption that we will continue on this trendline is a safe, reasonable and practical one for me. I think this is true for most people.

## A Reasonable Starter Opinion

In my industry and in my role, having worked in AI and "AI adjacent" software for the last many years, I've felt like the burden of proof has shifted for me. Given the observable trajectory, the consistent pace of development, and the massive economic incentives at play, a reasonable starter opinion has to be that AI will fundamentally impact how we work.

So for me, it's less about **if** AI is going to cause a major shift in how we work. That ship has sailed. But instead it's the How and the When. My questions are a lot more practical and personal: What is a reasonable rate of change to expect for me? What will a software engineer's job look like in 2 years if LLM models get 200% better at writing code? What parts of the software development lifecycle will "still remain" if claude becomes perfect? Do I have 2 years, 5 years or 25 years left of doing work like I am doing?

This isn't about being an AI optimist or pessimist. It's about being realistic. Even if you believe AI development will slow down, even if you think the current capabilities are overhyped, even if you're skeptical about the timeline, you still need to form an opinion about what these things actually mean in practical terms for your job, career and industry.

## Why We're Writing

I am finding a lot of AI writing that is very technically deep (interesting to software developers, but not much else) or very sensationalist. But, I've found it to be hard to find real data to back up realistic assertions of what the next 5 years looks like for those of who are working in knowledge work fields. A lot of content is written by technologists who may not understand your industry and industry leaders who may not be working directly with technology.

We believe the most valuable perspectives will come from people who are willing to engage seriously with bothâ€”to test the tools, study the trends, and think carefully about what it all means for the actual work they do.

This is why we're launching this project. It's going to be a collection of articles, thoughts and projects all aimed at trying to understnd AI and AI-adjacent technologies. And, you know, anything else that we're thinking about at the moment. We're going to try to cut through the hype and just think practically and honestly about AI. We're calling it our "research lab."

We know that there are many people, just like us, who are asking the same questions - and we hope to build a small community. We'll be publishing our philosophy shortly: but, in brief, we want to be democratic, open-source, thoughtful and widely understandable.

Over the coming months, we'll be diving deep into specific trends, testing emerging tools, and sharing what we learn. Hopefully we can help inform your "reasonable starter opinion" about what AI means for you.

We'd love to have you join!
